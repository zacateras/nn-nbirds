{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nn-nbirds.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zacateras/nn-nbirds/blob/master/report_colab.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "YShRmkT8DMW5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Michał Sitko \\\n",
        "Michał Chmielowiec \\\n",
        "Andrzej Dawidziuk \\\n",
        "\n",
        "# Neural Networks (SNR) 2018L - Preliminary Report\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "Sbo5rRPSmrYx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We decided to use [Google Collaboratory](https://colab.research.google.com) as a main platform for project development. So called Colab was developed by Google internally from year 2014 as a tool dedicated for machine learning reaserch. Now it is publicly available as a side Google Drive service.\n",
        "\n",
        "Colab is an online version of Jupyter Notebook - a web application that allows its users to create and share documents that contain live code, equations, visualizations and narrative text. Usually Jupyter Notebooks are hosted locally on researchers' machines. Very often these machines are not equipped with processing units suited for complex calculations. Locally prepared Jupyter reports are printed as PDF documents and then statically distributed.\n",
        "\n",
        "Google Colab provides online version of Jupyter server with exposed by very convenient web interface. Each Google Drive account is allowed to use one Jupyter Notebook environment. Technically, environments are setup inside cloud hosted, UNIX type, Docker containers. The containers' virtual hard drives can expand to the maximum space available for particular account in its Google Drive service. Furthermore the container environment has access to pretty powerful computing resources: quad core CPU and Tesla K80 GPU. We should note here that those resources are shared by multiple users and thus its base performance may vary.\n",
        "\n",
        "This report was prepared in Colab."
      ]
    },
    {
      "metadata": {
        "id": "2YRBDHnKwHX5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's ensure that the installed Python version is at least 3.6. It happens occasionally that containers are initialized with Python 2.7 kernels despite the fact that they are the higher is configured. In such situation the hypervisor should be rebooted (i.e. by invoking a kill command)."
      ]
    },
    {
      "metadata": {
        "id": "UvFrie12LmWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9ff8644-d291-4887-a36e-4f8620be21c3"
      },
      "cell_type": "code",
      "source": [
        "# If python3 is not loaded kill the hypervisor\n",
        "# ! kill -9 -1\n",
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.3 (default, Oct  3 2017, 21:45:48) \\n[GCC 7.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "XjnR7ja23LDp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will clone the project repository and install required pip packages. Interactive shell can be accessed inline by prefixing commands with an exclamation mark (!)."
      ]
    },
    {
      "metadata": {
        "id": "Wb6yct3-XdMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "bb62aed6-09d9-46c9-f7cc-8be7e93f845c"
      },
      "cell_type": "code",
      "source": [
        "% cd ~\n",
        "\n",
        "# Remove the environment\n",
        "! if [ -d \"nn-nbirds\" ]; then rm -rf \"nn-nbirds\"; fi\n",
        "# ! pip freeze | xargs pip uninstall -y\n",
        "\n",
        "# Build the environment \n",
        "! git clone https://github.com/zacateras/nn-nbirds.git\n",
        "% cd ./nn-nbirds\n",
        "! pip install -r requirements.txt > pip.log\n",
        "# Those below fixes the issue with keras @ Colab\n",
        "! pip install Pillow==4.0.0 -q\n",
        "! pip install PIL -q\n",
        "! pip install image -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'nn-nbirds'...\n",
            "remote: Counting objects: 90, done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 90 (delta 44), reused 61 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n",
            "/content/nn-nbirds\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kR5kwNaflYO9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The whole nbirds database was stored in dropbox as a zip blob. We prepared automated shell script for downloading and unzipping it. Let's use it now."
      ]
    },
    {
      "metadata": {
        "id": "j8ESpbziYk61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "563839a8-5d4f-4691-9938-2253beeb1ce3"
      },
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "! ./download.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-27 21:57:30--  https://www.dropbox.com/s/fi2g3zxsn0pdmn1/nbirds.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:6022:1::a27d:4201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl.dropboxusercontent.com/content_link/QNQw0sdwaubYwbUc3BkpoHQZlN2U0D0jSqNDVPkJkRoyxFrQ7FIBMSSlyugEGIDU/file [following]\n",
            "--2018-04-27 21:57:30--  https://dl.dropboxusercontent.com/content_link/QNQw0sdwaubYwbUc3BkpoHQZlN2U0D0jSqNDVPkJkRoyxFrQ7FIBMSSlyugEGIDU/file\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 623160299 (594M) [application/zip]\n",
            "Saving to: ‘/content/nn-nbirds/data/nbirds.zip’\n",
            "\n",
            "/content/nn-nbirds/ 100%[===================>] 594.29M  32.3MB/s    in 19s     \n",
            "\n",
            "2018-04-27 21:57:51 (30.5 MB/s) - ‘/content/nn-nbirds/data/nbirds.zip’ saved [623160299/623160299]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K22c_cr5mBU-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Colab runtime can provide stable and fast internet connection. ~45MB/s average download speed should be noted here."
      ]
    },
    {
      "metadata": {
        "id": "qLIvo2acDi_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Database analysis\n",
        "Dostarczona baza danych zawiera 48562 zdjęć ptaków należących do 555 klas (gatunków). Rozkład liczby zdjęć należących do poszczególnych klas przedstawia Wykres 1. Puste miejsca na histogramie świadczą o większej ilości klas niż wynika to ze zbioru zdjęć, co zostało wyjaśnione niżej. \\\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YJPRqsvmfI3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6b59ae3d-6810-46dc-a984-dc7138e2028d"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#show database content chart\n",
        "\n",
        "data = np.genfromtxt('data/image_class_labels.txt', delimiter=' ', usecols = (1),\n",
        "                    dtype=int)\n",
        "          \n",
        "unique, counts = np.unique(data, return_counts=True)\n",
        "plt.bar(unique, counts)\n",
        "plt.ylabel('Liczba zdjec w klasie')\n",
        "plt.xlabel('Numer klasy')\n",
        "plt.title('Wykres 1. Rozkład liczby zdjęć w poszczególnych klasach')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efeea7a2320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "m5yImoI0EYu3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ponieważ poszczególne klasy odpowiadają konkretnym gatunkom ptaków, możliwym było zbudowanie hierarchii klas przypominającej biologiczną systematykę organizmów. Taka hierarchia została dostarczona wraz z bazą, a jej drzewo w formie graficznej przedstawia wygenerowany w trakcie prac nad projektem obraz w formacie SVG dostępny w postaci poniższego linku: \\\n",
        "[Hierarchia klas ptaków](http://mion.elka.pw.edu.pl/~mchmielo/tmp/nbirds_hierarchy.svg) \\\n",
        "Wszystkich klas w hierarchii jest 1011. Oprócz informacji na temat przynależności zdjęć do poszczególnych klas oraz samej hierarchii klas, baza dostarcza informacje na temat Autorów oraz rozmiarów zdjęć. Ważną informacją zawartą w bazie są rozmiary *bounding box* czyli rozmiarów najmniejszych prostokątów w których zawarte są w całości obiekty będące przedstawicielami poszczególnych gatunków ptaków na badanych zdjęciach. Pozwoliło to znacznie ograniczyć rozmiar danych do klasyfikatora. Nazwy plików graficznych są powiązane z wyżej opisanymi danymi za pomocą unikalnych identyfikatorów *image_guid*. Zależności pomiędzy plikami bazy dobrze odzwierciedla Diagram 1. \\\n",
        " \\\n",
        "**Diagram 1** Wizualizacja powiązań plików bazy danych ![Diagram 1](https://raw.githubusercontent.com/zacateras/nn-nbirds/master/assets/dataset.png) \\"
      ]
    },
    {
      "metadata": {
        "id": "pwRHQ6Eq6GAG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will load our script for metadata loading & dataset preprocessing."
      ]
    },
    {
      "metadata": {
        "id": "h2rzamJxg582",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from preprocess import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_E1Bck1hJnf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "fd0454a9-9e6d-441c-ab34-3f8512290ccb"
      },
      "cell_type": "code",
      "source": [
        "ds_meta = build_ds_meta()\n",
        "\n",
        "for ds_meta_item in ds_meta:\n",
        "    print('Quantity of %s: %s' % (ds_meta_item, ds_meta[ds_meta_item].count()[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantity of bounding_boxes: 48562\n",
            "Quantity of classes: 1011\n",
            "Quantity of hierarchy: 1010\n",
            "Quantity of image_class_labels: 48562\n",
            "Quantity of images: 48562\n",
            "Quantity of photographers: 48562\n",
            "Quantity of sizes: 48562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4bzzUG467Eiw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to prepare dataset images library for feature extraction we shall apply a few transformations. Let's define and execute them here. All pictures will be cropped with bounding boxes defined in metadata, resized to 150 / 150 dimensions, converted to grayscale and transformed with Gabor filter. Hyperparameters of the filter were adjusted, so that different color and contrast bounderies are exposed. New images will be copied to the separate folder, after then the whole dataset will be divided into train, cross-validation and test parts in (0.7 / 0.2 / 0.1 proportion)."
      ]
    },
    {
      "metadata": {
        "id": "-POd5m4EiA7G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Transform:\n",
        "  def __init__(self, img, guid, ds_meta):\n",
        "    self.img = img\n",
        "    self.guid = guid\n",
        "    self.ds_meta = ds_meta\n",
        "  \n",
        "  def resize(self):\n",
        "      img = cv2.resize(self.img, (150, 150))\n",
        "      return self\n",
        "\n",
        "  def greyscale(self):\n",
        "      img = cv2.cvtColor(self.img, cv2.COLOR_BGR2GRAY)\n",
        "      return self\n",
        "\n",
        "  def gabor_filter(self):\n",
        "      g_kernel = cv2.getGaborKernel((15, 15), 0.66, np.pi/8, 1.3, 0.5, 0, ktype=cv2.CV_32F)\n",
        "\n",
        "      img = cv2.normalize(cv2.filter2D(self.img, cv2.CV_8UC3, g_kernel),\n",
        "                           None,\n",
        "                           alpha=0,\n",
        "                           beta=255,\n",
        "                           norm_type=cv2.NORM_MINMAX,\n",
        "                           dtype=cv2.CV_32F)\n",
        "      \n",
        "      return self\n",
        "\n",
        "# BASE               SET_A\n",
        "# + Bounding box  => SET_A_BB               (del)\n",
        "# + Gabor filter  => SET_A_BB_GF            (del)\n",
        "# + TVT splitting => SET_A_BB_GF_train\n",
        "#                    SET_A_BB_GF_validation\n",
        "#                    SET_A_BB_GF_test\n",
        "\n",
        "apply(bounding_box, 'data/SET_A', 'data/SET_A_BB', ds_meta)\n",
        "apply(lambda img, guid, dsm: Transform(img, guid, ds_meta).resize().greyscale().gabor_filter().img, 'data/SET_A_BB', 'data/SET_A_BB_GF', ds_meta)\n",
        "apply_tvt_split('data/SET_A_BB_GF', train=0.7, test=0.2, validation=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9528Ww0IDw_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example images before and after transformation are presented below:\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacateras/nn-nbirds/master/assets/sample_before.jpg =320x220) ![](https://raw.githubusercontent.com/zacateras/nn-nbirds/master/assets/sample_after.jpg =220x220)"
      ]
    },
    {
      "metadata": {
        "id": "uAZffQWB_P7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For building the model we will use Keras library. It is a high level deep neural network modeling toolset. It enables professionals to quickly prototype and train very complex networks, also it provides a rich set of functionalities for input data preprocessing, result model validation and many other. We will try to show a few of those functionalities in this report (and its continuation)."
      ]
    },
    {
      "metadata": {
        "id": "Wd0KwtxVB33U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Keras can run on top of different low level machine learning frameworks such as [TensorFlow](https://www.tensorflow.org/), [CNTK](https://docs.microsoft.com/pl-pl/cognitive-toolkit/), [Theano](http://www.deeplearning.net/software/theano/). We will stick to the most popular one with the most mature community."
      ]
    },
    {
      "metadata": {
        "id": "Bg0yoHp1iF3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85235028-b621-4d60-b25d-a069b399a2c7"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZoLxEzzYDR6g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "GPU device is available!"
      ]
    },
    {
      "metadata": {
        "id": "NKZL5ACblgQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edd4c80c-2aae-49e5-c1eb-099fdcfb490e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "slzm0OuhDXL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By calling appropriate backend methods we can get some more specific info concerning processing devices that are available."
      ]
    },
    {
      "metadata": {
        "id": "AL_Ws1eo0CQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "5c298f38-3b28-469f-cbf3-60c2f334eec8"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 3488870340712929096, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11288962663\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 13989086740330256603\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "AonKejzcjJ1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "74f23b1f-dda7-417c-efea-2ad4dca48998"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_labels = os.listdir('data/SET_A_BB_GF_train')\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'data/SET_A_BB_GF_train',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'data/SET_A_BB_GF_validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(150, 150, 1))) \n",
        "model.add(Dense(4))\n",
        "model.add(Dense(8))\n",
        "model.add(Dense(len(train_labels)))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=2000 // batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2103 images belonging to 50 classes.\n",
            "Found 300 images belonging to 50 classes.\n",
            "Epoch 1/50\n",
            "62/62 [==============================] - 19s 301ms/step - loss: 4.0976 - acc: 0.0131 - val_loss: 4.0922 - val_acc: 0.0267\n",
            "Epoch 2/50\n",
            "62/62 [==============================] - 18s 295ms/step - loss: 4.0191 - acc: 0.0214 - val_loss: 3.9231 - val_acc: 0.0317\n",
            "Epoch 3/50\n",
            "62/62 [==============================] - 18s 284ms/step - loss: 3.9644 - acc: 0.0307 - val_loss: 3.9642 - val_acc: 0.0183\n",
            "Epoch 4/50\n",
            "62/62 [==============================] - 17s 273ms/step - loss: 4.0288 - acc: 0.0151 - val_loss: 3.8990 - val_acc: 0.0217\n",
            "Epoch 5/50\n",
            "29/62 [=============>................] - ETA: 4s - loss: 3.9001 - acc: 0.0312"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 17s 278ms/step - loss: 3.9264 - acc: 0.0267 - val_loss: 3.8858 - val_acc: 0.0267\n",
            "Epoch 6/50\n",
            "62/62 [==============================] - 17s 274ms/step - loss: 3.8777 - acc: 0.0292 - val_loss: 3.8539 - val_acc: 0.0267\n",
            "Epoch 7/50\n",
            "62/62 [==============================] - 17s 279ms/step - loss: 3.8429 - acc: 0.0358 - val_loss: 3.9033 - val_acc: 0.0250\n",
            "Epoch 8/50\n",
            "62/62 [==============================] - 17s 275ms/step - loss: 3.8656 - acc: 0.0328 - val_loss: 3.8316 - val_acc: 0.0333\n",
            "Epoch 9/50\n",
            "62/62 [==============================] - 17s 273ms/step - loss: 3.8292 - acc: 0.0393 - val_loss: 3.8416 - val_acc: 0.0383\n",
            "Epoch 10/50\n",
            "18/62 [=======>......................] - ETA: 4s - loss: 3.8102 - acc: 0.0399"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 17s 278ms/step - loss: 3.8207 - acc: 0.0388 - val_loss: 3.8232 - val_acc: 0.0183\n",
            "Epoch 11/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 3.8490 - acc: 0.0408"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZAuVlUVHEDpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "#### Google Colab\n",
        "* [Colab Teaser](https://hackernoon.com/train-your-machine-learning-models-on-googles-gpus-for-free-forever-a41bd309d6ad)\n",
        "* [Simple Colab Example](https://towardsdatascience.com/fast-ai-lesson-1-on-google-colab-free-gpu-d2af89f53604)\n",
        "* [Extensive Colab Example](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)\n",
        "\n",
        "#### Gabor Filters\n",
        "* [Practical overview of Gabor Filters](https://cvtuts.wordpress.com/2014/04/27/gabor-filters-a-practical-overview/)\n",
        "* [Library for testing various filter configurations](http://nbviewer.jupyter.org/github/bicv/LogGabor/blob/master/LogGabor.ipynb)\n",
        "* [Example of applying OpenCV implementation in Python](https://gist.github.com/kendricktan/93f0da88d0b25087d751ed2244cf770c)\n",
        "* [Feature extraction in face recognition task](https://pdfs.semanticscholar.org/3cf9/e4bc906ee4d15b69b34db413f8e319692e3b.pdf)\n",
        "* [Feature extraction in car recognition task](http://scholar.google.pl/scholar_url?url=http://www.academia.edu/download/3448045/Car_recognition_using_gabor_filter_feature_extraction.doc&hl=pl&sa=X&scisig=AAGBfm2C3mPP89cH7bXDsFiXMDNPLIY27Q&nossl=1&oi=scholarr&ved=0ahUKEwizv5bdgdTaAhXEGuwKHXy-AY0QgAMIKSgCMAA)\n",
        "\n",
        "#### DNNs in Keras\n",
        "* [Keras documentation](https://keras.io/)"
      ]
    }
  ]
}