{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_nbirds_report.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UvFrie12LmWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7fdf9e6-1562-41c9-f625-29ba27d0298f"
      },
      "cell_type": "code",
      "source": [
        "# If python2 is not loaded kill the hypervisor\n",
        "# ! kill -9 -1\n",
        "import sys\n",
        "sys.version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.7.14 (default, Sep 23 2017, 22:06:14) \\n[GCC 7.2.0]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Wb6yct3-XdMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "fffd2fd7-83db-40e6-df1e-d61c1d5feea3"
      },
      "cell_type": "code",
      "source": [
        "% cd ~\n",
        "\n",
        "# Remove the environment\n",
        "! if [ -d \"nn-nbirds\" ]; then rm -rf \"nn-nbirds\"; fi\n",
        "# ! pip freeze | xargs pip uninstall -y\n",
        "\n",
        "# Build the environment \n",
        "! git clone https://github.com/zacateras/nn-nbirds.git\n",
        "% cd ./nn-nbirds\n",
        "! pip install -r requirements.txt > pip.log\n",
        "# The commands below fix the issue with Keras @ Colab\n",
        "! pip install Pillow==4.0.0 -q\n",
        "! pip install PIL -q\n",
        "! pip install image -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'nn-nbirds'...\n",
            "remote: Counting objects: 262, done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 262 (delta 24), reused 37 (delta 12), pack-reused 205\u001b[K\n",
            "Receiving objects: 100% (262/262), 98.72 MiB | 12.35 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n",
            "/content/nn-nbirds\n",
            "\u001b[31m  Could not find a version that satisfies the requirement ipython==6.3.1 (from -r requirements.txt (line 15)) (from versions: 0.10, 0.10.1, 0.10.2, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.13.2, 1.0.0, 1.1.0, 1.2.0, 1.2.1, 2.0.0, 2.1.0, 2.2.0, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 3.0.0, 3.1.0, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 4.0.0b1, 4.0.0, 4.0.1, 4.0.2, 4.0.3, 4.1.0rc1, 4.1.0rc2, 4.1.0, 4.1.1, 4.1.2, 4.2.0, 4.2.1, 5.0.0b1, 5.0.0b2, 5.0.0b3, 5.0.0b4, 5.0.0rc1, 5.0.0, 5.1.0, 5.2.0, 5.2.1, 5.2.2, 5.3.0, 5.4.0, 5.4.1, 5.5.0, 5.6.0, 5.7.0)\u001b[0m\n",
            "\u001b[31mNo matching distribution found for ipython==6.3.1 (from -r requirements.txt (line 15))\u001b[0m\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j8ESpbziYk61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "a81677c4-90dc-48c2-ee92-672974053cc9"
      },
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "! ./data_tools/download.sh\n",
        "\n",
        "# Split the dataset\n",
        "! ./data_tools/split.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-06-11 20:46:31--  https://www.dropbox.com/s/fi2g3zxsn0pdmn1/nbirds.zip\r\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.1, 2620:100:6016:1::a27d:101\r\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc845f72041511d8df009a131e06.dl.dropboxusercontent.com/cd/0/get/AInsatevfaAUExqMvgkHJk2QkM_p0raTqKV4CqgXmaxUiymrwBtYI2nLzQbAToJoWEpj9qX5vcAELfrS6wCISvifs6S0LUUjcOgiD-2j_vFgx5WBdp4HE1LkAbOoi_mc555P6iehWavA8k6sWWQfzo_7ICdGjNGS8zF84ar9GbFOFSPKhaA1N8A3A7U0-1nKf2o/file [following]\n",
            "--2018-06-11 20:46:31--  https://uc845f72041511d8df009a131e06.dl.dropboxusercontent.com/cd/0/get/AInsatevfaAUExqMvgkHJk2QkM_p0raTqKV4CqgXmaxUiymrwBtYI2nLzQbAToJoWEpj9qX5vcAELfrS6wCISvifs6S0LUUjcOgiD-2j_vFgx5WBdp4HE1LkAbOoi_mc555P6iehWavA8k6sWWQfzo_7ICdGjNGS8zF84ar9GbFOFSPKhaA1N8A3A7U0-1nKf2o/file\n",
            "Resolving uc845f72041511d8df009a131e06.dl.dropboxusercontent.com (uc845f72041511d8df009a131e06.dl.dropboxusercontent.com)... 162.125.7.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uc845f72041511d8df009a131e06.dl.dropboxusercontent.com (uc845f72041511d8df009a131e06.dl.dropboxusercontent.com)|162.125.7.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 623160299 (594M) [application/zip]\n",
            "Saving to: ‘/content/nn-nbirds/data/nbirds.zip’\n",
            "\n",
            "/content/nn-nbirds/ 100%[===================>] 594.29M  29.4MB/s    in 21s     \n",
            "\n",
            "2018-06-11 20:46:53 (28.6 MB/s) - ‘/content/nn-nbirds/data/nbirds.zip’ saved [623160299/623160299]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kYobBxVUuorm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cdf7ebab-81cc-450c-e4fb-b24b0e95a791"
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "! pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def synchronize_dir(drive, drive_dir, local_dir):\n",
        "  print('Synchronizing %s with %s...' % (drive_dir, local_dir))\n",
        "  drive_items = [{ 'id': item['id'], 'title': item['title'], 'mimeType': item['mimeType']} for item in drive.ListFile({'q': \"'%s' in parents and trashed=false\" % drive_dir['id']}).GetList()]\n",
        "  local_items = os.listdir(local_dir)\n",
        "  local_items_to_upload = [item for item in os.listdir(local_dir) if item not in map(lambda x: x['title'], drive_items)]\n",
        "  \n",
        "  for local_item_to_upload in local_items_to_upload:\n",
        "    local_item_to_upload_abs = os.path.join(local_dir, local_item_to_upload)\n",
        "    if os.path.isfile(local_item_to_upload_abs):\n",
        "      print('Creating file %s...' % local_item_to_upload_abs)\n",
        "      file = drive.CreateFile({ 'parents': [{ 'kind': 'drive#childList', 'id': drive_dir['id']}], 'title': local_item_to_upload })\n",
        "      file.SetContentFile(local_item_to_upload_abs)\n",
        "      file.Upload()\n",
        "    elif os.path.isdir(local_item_to_upload_abs):\n",
        "      print('Creating directory %s...' % local_item_to_upload_abs)\n",
        "      directory = drive.CreateFile({ 'parents': [{ 'kind': 'drive#childList', 'id': drive_dir['id']}], 'title': local_item_to_upload, 'mimeType': 'application/vnd.google-apps.folder' })\n",
        "      directory.Upload()\n",
        "      \n",
        "  for local_subdir in [item for item in os.listdir(local_dir) if os.path.isdir(os.path.join(local_dir, item))]:\n",
        "    child_drive_dir = [{ 'id': item['id'], 'title': item['title']} for item in drive.ListFile({'q': \"'%s' in parents and title='%s' and trashed=false\" % (drive_dir['id'], local_subdir)}).GetList()][0]\n",
        "    child_local_dir = os.path.join(local_dir, local_subdir)\n",
        "    \n",
        "    synchronize_dir(drive, child_drive_dir, child_local_dir)\n",
        "  \n",
        "def synchronize_all(drive):\n",
        "  drive_root_dirs = [{ 'id': item['id'], 'title': item['title']} for item in drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList() if item['title'] in ['nn-nbirds']][0]\n",
        "  drive_sync_dirs = [{ 'id': item['id'], 'title': item['title']} for item in drive.ListFile({'q': \"'%s' in parents and trashed=false\" % drive_root_dirs['id']}).GetList() if item['title'] in ['logs', 'cnn_models']]\n",
        "\n",
        "  # TODO : Create directories structure\n",
        "  # /nn-nbirds\n",
        "  #   /cnn_models\n",
        "  #   /logs\n",
        "  \n",
        "  for drive_sync_dir in drive_sync_dirs:\n",
        "    synchronize_dir(drive, drive_sync_dir, drive_sync_dir['title'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKZL5ACblgQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba71b341-6ea7-4590-a177-4d4d83b34ca3"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "AL_Ws1eo0CQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "9d49263e-d141-48ac-dd98-e935fd09fa37"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 5798377902409491951, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11189098906\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12098346462585819481\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "-GgA63WnTiWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "be8758c4-1138-4a01-af74-c7cb22c099ec"
      },
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "from preprocess import clip, resize\n",
        "from generators import Generators\n",
        "\n",
        "from models.custom_dnn import custom_dnn\n",
        "\n",
        "def process_custom(epochs, batch_size, width, height, descriptor_size, filter_size, filter_number, kernel_reg, kernel_reg_name):\n",
        "    model_code = 'cnn_w%s_h%s_%s_descr_%s_x_%s_%s_filt_%s_batch_%s_reg_%s_epochs' % (width, height, descriptor_size, filter_number, filter_size[0], filter_size[1], batch_size, kernel_reg_name, epochs)\n",
        "    model_path = 'cnn_models/%s.h5' % model_code\n",
        "    model_logs_path = 'logs/%s' % model_code\n",
        "    \n",
        "    if os.path.exists(model_path):\n",
        "      print('Model %s already exists! Skipping execution.' % model_code)\n",
        "      return\n",
        "    else:\n",
        "      print('Training model %s...' % model_code)\n",
        "    \n",
        "    if os.path.exists(model_logs_path):\n",
        "      shutil.rmtree(model_logs_path)\n",
        "    os.makedirs(model_logs_path)\n",
        "    os.makedirs('%s/tb' % model_logs_path)\n",
        "    os.makedirs('%s/checkpoints' % model_logs_path) \n",
        "    \n",
        "    # preprocess\n",
        "    clip()\n",
        "    resize(width, height)\n",
        "    \n",
        "    # generators\n",
        "    g = Generators(width=width, height=height, batch_size=batch_size)\n",
        "\n",
        "    (g_train, cnt_train) = g.train()\n",
        "    (g_validation, cnt_validation) = g.validation()\n",
        "    (g_test, cnt_test) = g.test()\n",
        "    \n",
        "    model = custom_dnn(\n",
        "      width=width,\n",
        "      height=height,\n",
        "      output=cnt_train,\n",
        "      descriptor_size=descriptor_size,\n",
        "      filter_size=filter_size,\n",
        "      filter_number=filter_number,\n",
        "      kernel_reg=kernel_reg,\n",
        "      kernel_reg_name=kernel_reg_name)\n",
        "\n",
        "    cb_tb = keras.callbacks.TensorBoard(\n",
        "      log_dir='%s/tb' % model_logs_path,\n",
        "      histogram_freq=0,\n",
        "      batch_size=batch_size,\n",
        "      write_graph=True,\n",
        "      write_grads=False,\n",
        "      write_images=True)\n",
        "\n",
        "    cb_mc = keras.callbacks.ModelCheckpoint(\n",
        "      filepath='%s/checkpoints/weights-{epoch:02d}.hdf5' % model_logs_path,\n",
        "      verbose=1)\n",
        "\n",
        "    model.fit_generator(\n",
        "      g_train,\n",
        "      steps_per_epoch=2000 // batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=g_validation,\n",
        "      validation_steps=800 // batch_size,\n",
        "      callbacks=[cb_tb]) # ModelCheckpointer was removed due to significant size of generated checkpoint files\n",
        "\n",
        "    model.save(model_path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPBVkBwzX19l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6544c707-d5c0-4eac-c54b-36c3db6d40be"
      },
      "cell_type": "code",
      "source": [
        "# Start tensorboard & expose via localtunnel\n",
        "! npm install -g localtunnel > npm-lt.log\n",
        "get_ipython().system_raw('tensorboard --logdir logs --host 0.0.0.0 --port 6006 &')\n",
        "get_ipython().system_raw('lt --port 6006 > url.txt 2>&1 &')\n",
        "! cat url.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hyour url is: https://stale-turtle-89.localtunnel.me\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_b0SzLsVTiWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "19bcd7fe-3488-40b9-b461-b1faff1e8ac5"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import os\n",
        "from itertools import product\n",
        "\n",
        "epochss=[150]\n",
        "batch_sizes=[128, 32, 64]\n",
        "dims=[(64, 64), (128, 128), (256, 256)]\n",
        "\n",
        "descriptor_sizes=[512, 1024, 256]\n",
        "filter_sizes=[(3, 3), (5, 5)]\n",
        "filter_numbers=[32, 16]\n",
        "keras_regs=[(None, None), (keras.regularizers.l1(0.01), 'L1(0.01)'), (keras.regularizers.l2(0.01), 'L2(0.01)')]\n",
        "\n",
        "for item in product(epochss, batch_sizes, dims, descriptor_sizes, filter_sizes, filter_numbers, keras_regs):\n",
        "    epochs = item[0]\n",
        "    batch_size = item[1]\n",
        "    width = item[2][0]\n",
        "    height = item[2][1]\n",
        "    \n",
        "    descriptor_size = item[3]\n",
        "    filter_size = item[4]\n",
        "    filter_number = item[5]\n",
        "    kernel_reg = item[6][0]\n",
        "    kernel_reg_name = item[6][1]\n",
        "    \n",
        "    process_custom(epochs, batch_size, width, height, descriptor_size, filter_size, filter_number, kernel_reg, kernel_reg_name)\n",
        "    synchronize_all(drive)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model cnn_w64_h64_512_descr_32_x_3_3_filt_128_batch_None_reg_150_epochs...\n",
            "Clipping train set...\n",
            "Clipping validation set...\n",
            "Clipping test set...\n",
            "Resizing train set...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C-5HXuKm7wkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "982e4310-1e49-4b08-d8f6-73eaa1f06043"
      },
      "cell_type": "code",
      "source": [
        "! git config --global user.email \"USERMAIL\"\n",
        "! git config --global user.name \"USERNAME\"\n",
        "! git add cnn_models/*\n",
        "! git commit -m \"cnn_models\"\n",
        "! git remote set-url origin https://USERNAME:PASSWORD@github.com/zacateras/nn-nbirds.git\n",
        "! git push"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 921e27a] cnn_models\r\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\r\n",
            " create mode 100644 cnn_models/cnn_512_descr_32_x_3_3_filt_128_batch_None_reg_120_epochs.h5\n",
            "Counting objects: 4, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 13.20 MiB | 5.81 MiB/s, done.\n",
            "Total 4 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/zacateras/nn-nbirds.git\n",
            "   c63d25a..921e27a  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n0-hHpWT54NS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "2fc995c6-41da-408e-b231-6d883e2d8066"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "results = []\n",
        "for filename in os.listdir('cnn_models'):\n",
        "  model = load_model('cnn_models/%s' % filename)\n",
        "  result = model.evaluate_generator(Generators(64, 64, 128).test()[0])\n",
        "  result.insert(0, filename)\n",
        "  results.insert(0, result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n",
            "Found 607 images belonging to 50 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xxkBW2DbAg4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "2dfed865-d4ab-4a64-ef15-a67a9ea2e607"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(results, columns=['name', 'loss', 'categorical_accuracy', 'top_5_categorical_accuracy']).sort_values('categorical_accuracy', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>loss</th>\n",
              "      <th>categorical_accuracy</th>\n",
              "      <th>top_5_categorical_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnn_w64_h64_512_descr_32_x_3_3_filt_128_batch_...</td>\n",
              "      <td>2.124778</td>\n",
              "      <td>0.563427</td>\n",
              "      <td>0.833608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cnn_512_descr_16_x_3_3_filt_128_batch_None_reg...</td>\n",
              "      <td>2.024395</td>\n",
              "      <td>0.489292</td>\n",
              "      <td>0.751236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cnn_512_descr_32_x_3_3_filt_128_batch_None_reg...</td>\n",
              "      <td>2.209090</td>\n",
              "      <td>0.461285</td>\n",
              "      <td>0.751236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cnn_512_descr_32_x_5_5_filt_128_batch_None_reg...</td>\n",
              "      <td>2.202366</td>\n",
              "      <td>0.397035</td>\n",
              "      <td>0.718287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>cnn_512_descr_32_x_3_3_filt_128_batch_l1(0.01)...</td>\n",
              "      <td>5.565352</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.103789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cnn_128_descr_32_x_3_3_filt_128_batch_l2(0.01)...</td>\n",
              "      <td>3.911947</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.105437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cnn_256_descr_32_x_3_3_filt_128_batch_None_reg...</td>\n",
              "      <td>3.911961</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.103789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>cnn_512_descr_32_x_3_3_filt_128_batch_l2(0.01)...</td>\n",
              "      <td>3.911969</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.103789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cnn_1024_descr_32_x_3_3_filt_128_batch_None_re...</td>\n",
              "      <td>3.911969</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.103789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cnn_256_descr_32_x_3_3_filt_128_batch_l2(0.01)...</td>\n",
              "      <td>3.911964</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.103789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cnn_128_descr_32_x_3_3_filt_128_batch_None_reg...</td>\n",
              "      <td>3.911984</td>\n",
              "      <td>0.021417</td>\n",
              "      <td>0.103789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 name      loss  \\\n",
              "0   cnn_w64_h64_512_descr_32_x_3_3_filt_128_batch_...  2.124778   \n",
              "4   cnn_512_descr_16_x_3_3_filt_128_batch_None_reg...  2.024395   \n",
              "1   cnn_512_descr_32_x_3_3_filt_128_batch_None_reg...  2.209090   \n",
              "7   cnn_512_descr_32_x_5_5_filt_128_batch_None_reg...  2.202366   \n",
              "9   cnn_512_descr_32_x_3_3_filt_128_batch_l1(0.01)...  5.565352   \n",
              "2   cnn_128_descr_32_x_3_3_filt_128_batch_l2(0.01)...  3.911947   \n",
              "8   cnn_256_descr_32_x_3_3_filt_128_batch_None_reg...  3.911961   \n",
              "10  cnn_512_descr_32_x_3_3_filt_128_batch_l2(0.01)...  3.911969   \n",
              "6   cnn_1024_descr_32_x_3_3_filt_128_batch_None_re...  3.911969   \n",
              "3   cnn_256_descr_32_x_3_3_filt_128_batch_l2(0.01)...  3.911964   \n",
              "5   cnn_128_descr_32_x_3_3_filt_128_batch_None_reg...  3.911984   \n",
              "\n",
              "    categorical_accuracy  top_5_categorical_accuracy  \n",
              "0               0.563427                    0.833608  \n",
              "4               0.489292                    0.751236  \n",
              "1               0.461285                    0.751236  \n",
              "7               0.397035                    0.718287  \n",
              "9               0.021417                    0.103789  \n",
              "2               0.021417                    0.105437  \n",
              "8               0.021417                    0.103789  \n",
              "10              0.021417                    0.103789  \n",
              "6               0.021417                    0.103789  \n",
              "3               0.021417                    0.103789  \n",
              "5               0.021417                    0.103789  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}