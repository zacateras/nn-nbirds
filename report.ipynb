{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset\n",
    "\n",
    "![](assets/dataset.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def tvt_split(path, train=0.7, test=0.3, validation=0.0, class_subdirs=True):\n",
    "    dir_train_p = '%s_train' % path\n",
    "    dir_validation_p = '%s_validation' % path\n",
    "    dir_test_p = '%s_test' % path\n",
    "    \n",
    "    if os.path.exists(dir_train_p) and os.path.isdir(dir_train_p):\n",
    "        shutil.rmtree(dir_train_p)\n",
    "    if os.path.exists(dir_validation_p) and os.path.isdir(dir_validation_p):\n",
    "        shutil.rmtree(dir_validation_p)\n",
    "    if os.path.exists(dir_test_p) and os.path.isdir(dir_test_p):\n",
    "        shutil.rmtree(dir_test_p)\n",
    "        \n",
    "    subdirs = [''] if not class_subdirs else os.listdir(path)\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        subdir_p = os.path.join(*(path, subdir))\n",
    "        subdir_list = os.listdir(subdir_p)\n",
    "        \n",
    "        random.shuffle(subdir_list)\n",
    "        \n",
    "        subdir_list_len = len(subdir_list)\n",
    "        subdir_list_train_thld = int(subdir_list_len * train)\n",
    "        subdir_list_validation_thld = int(subdir_list_len * validation) + subdir_list_train_thld\n",
    "        \n",
    "        subdir_list_train = subdir_list[:subdir_list_train_thld]\n",
    "        subdir_list_validation = subdir_list[subdir_list_train_thld:subdir_list_validation_thld]\n",
    "        subdir_list_test = subdir_list[subdir_list_validation_thld:]\n",
    "        \n",
    "        # prepare train part\n",
    "        subdir_train_p = os.path.join(*(dir_train_p, subdir))\n",
    "        os.makedirs(subdir_train_p, exist_ok=True)\n",
    "        for subdir_list_train_item in subdir_list_train:\n",
    "            src = os.path.join(subdir_p, subdir_list_train_item)\n",
    "            dest = os.path.join(subdir_train_p, subdir_list_train_item)\n",
    "            shutil.copyfile(src, dest)\n",
    "            \n",
    "        # prepare validation part\n",
    "        if len(subdir_list_validation) > 0:\n",
    "            subdir_validation_p = os.path.join(*(dir_validation_p, subdir))\n",
    "            os.makedirs(subdir_validation_p, exist_ok=True)\n",
    "            for subdir_list_validation_item in subdir_list_validation:\n",
    "                src = os.path.join(subdir_p, subdir_list_validation_item)\n",
    "                dest = os.path.join(subdir_validation_p, subdir_list_validation_item)\n",
    "                shutil.copyfile(src, dest)\n",
    "            \n",
    "        # prepare test part\n",
    "        subdir_test_p = os.path.join(*(dir_test_p, subdir))\n",
    "        os.makedirs(subdir_test_p, exist_ok=True)\n",
    "        for subdir_list_test_item in subdir_list_test:\n",
    "            src = os.path.join(subdir_p, subdir_list_test_item)\n",
    "            dest = os.path.join(subdir_test_p, subdir_list_test_item)\n",
    "            shutil.copyfile(src, dest)\n",
    "            \n",
    "tvt_split('data/SET_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ds_meta_files = ['bounding_boxes', 'classes', 'hierarchy', 'image_class_labels', 'images', 'photographers', 'sizes']\n",
    "ds_meta = {}\n",
    "\n",
    "for ds_meta_file in ds_meta_files:\n",
    "    with open ('data/%s.txt' % ds_meta_file, 'r' ) as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    # TODO\n",
    "    # content = re.sub('\\ ([^\\ ]+)(\\ (.*))+(\\n|\\Z)', r'\\ \\1\\2\\3', content, flags = re.M)\n",
    "    content = re.sub('\\ (.*)(\\n|\\Z)', r'|\\1\\2', content, flags = re.M)\n",
    "    \n",
    "    with open ('data/%s.csv' % ds_meta_file, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    ds_meta[ds_meta_file] = pd.read_csv('data/%s.csv' % ds_meta_file, header=None, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of bounding_boxes: 48562\n",
      "Quantity of classes: 1011\n",
      "Quantity of hierarchy: 1010\n",
      "Quantity of image_class_labels: 48562\n",
      "Quantity of images: 48562\n",
      "Quantity of photographers: 48562\n",
      "Quantity of sizes: 48562\n"
     ]
    }
   ],
   "source": [
    "for ds_meta_item in ds_meta:\n",
    "    print('Quantity of %s: %s' % (ds_meta_item, ds_meta[ds_meta_item].count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sitkom/Code/nn-nbirds/venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3010 images belonging to 50 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 78s 623ms/step - loss: 8.7037 - acc: 0.0195\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 81s 644ms/step - loss: 8.7226 - acc: 0.0180\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 74s 594ms/step - loss: 8.6400 - acc: 0.0225\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 77s 618ms/step - loss: 8.6018 - acc: 0.0180\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 74s 596ms/step - loss: 8.7739 - acc: 0.0230\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 82s 653ms/step - loss: 8.7099 - acc: 0.0205\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 79s 630ms/step - loss: 8.7421 - acc: 0.0205\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 79s 631ms/step - loss: 8.5759 - acc: 0.0280\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 81s 647ms/step - loss: 8.7800 - acc: 0.0155\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 78s 623ms/step - loss: 8.7928 - acc: 0.0160\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 73s 587ms/step - loss: 8.6786 - acc: 0.0290\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 79s 635ms/step - loss: 8.6908 - acc: 0.0175\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 74s 592ms/step - loss: 8.7099 - acc: 0.0195\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 76s 612ms/step - loss: 8.7226 - acc: 0.0200\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 75s 603ms/step - loss: 8.6907 - acc: 0.0220\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 77s 615ms/step - loss: 8.8437 - acc: 0.0200\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 72s 580ms/step - loss: 8.5696 - acc: 0.0195\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 72s 578ms/step - loss: 8.9199 - acc: 0.0225\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 78s 623ms/step - loss: 8.6907 - acc: 0.0170\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 76s 605ms/step - loss: 8.8884 - acc: 0.0195\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 78s 621ms/step - loss: 8.5632 - acc: 0.0235\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 75s 598ms/step - loss: 8.7163 - acc: 0.0215\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 73s 586ms/step - loss: 8.8565 - acc: 0.0160\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 79s 634ms/step - loss: 8.6333 - acc: 0.0225\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 75s 602ms/step - loss: 8.8434 - acc: 0.0165\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 72s 576ms/step - loss: 8.7417 - acc: 0.0240\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 75s 598ms/step - loss: 8.7099 - acc: 0.0205\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 77s 618ms/step - loss: 8.9007 - acc: 0.0215\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 76s 608ms/step - loss: 8.5122 - acc: 0.0175\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 76s 607ms/step - loss: 8.7226 - acc: 0.0185\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 71s 570ms/step - loss: 8.9584 - acc: 0.0230\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 78s 627ms/step - loss: 8.4740 - acc: 0.0190\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 77s 617ms/step - loss: 8.8629 - acc: 0.0215\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 8.8373 - acc: 0.0160\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 71s 567ms/step - loss: 8.6589 - acc: 0.0235\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 70s 561ms/step - loss: 8.7545 - acc: 0.0180\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 70s 562ms/step - loss: 8.7545 - acc: 0.0220\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 72s 574ms/step - loss: 8.6911 - acc: 0.0190\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 78s 620ms/step - loss: 8.6716 - acc: 0.0210\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 79s 635ms/step - loss: 8.7417 - acc: 0.0205\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 77s 614ms/step - loss: 8.6722 - acc: 0.0195\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 72s 577ms/step - loss: 8.8820 - acc: 0.0225\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 74s 589ms/step - loss: 8.6015 - acc: 0.0205\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 73s 583ms/step - loss: 8.6907 - acc: 0.0185\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 72s 579ms/step - loss: 8.7098 - acc: 0.0210\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 71s 568ms/step - loss: 8.7860 - acc: 0.0165\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 74s 589ms/step - loss: 8.7418 - acc: 0.0240\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 74s 590ms/step - loss: 8.7290 - acc: 0.0215\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 72s 578ms/step - loss: 8.9071 - acc: 0.0135\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 73s 583ms/step - loss: 8.7353 - acc: 0.0240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1166fcda0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_labels = os.listdir('data/SET_A')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/SET_A',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    classes=train_labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(150, 150, 3))) \n",
    "model.add(Dense(64))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(len(train_labels)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. References\n",
    "\n",
    "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "* BSIF http://www.ee.oulu.fi/~jkannala/bsif/bsif.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
